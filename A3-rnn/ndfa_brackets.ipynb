{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6698,"status":"ok","timestamp":1638998685410,"user":{"displayName":"Bartek Boczek","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04109376448711217387"},"user_tz":-60},"id":"Iaw-VpSQBSMP","outputId":"1c7c3ca1-0453-45bc-ec38-7c0e400411ab"},"outputs":[],"source":["!pip install wget"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19607,"status":"ok","timestamp":1638998705013,"user":{"displayName":"Bartek Boczek","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04109376448711217387"},"user_tz":-60},"id":"tmBWClKoAayT","outputId":"1b41df9f-6d38-453b-be05-6ca5169dbdeb"},"outputs":[],"source":["# Setup the directory\n","from google.colab import drive\n","drive.mount('/content/drive')\n","import os\n","\n","from pathlib import Path\n","ROOT=Path(\"/content/drive/MyDrive/VU/deep_learning/A3\")\n","os.chdir(ROOT)\n","print(f'cdw = {os.getcwd()}')"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":2100,"status":"ok","timestamp":1638999805726,"user":{"displayName":"Bartek Boczek","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04109376448711217387"},"user_tz":-60},"id":"EP2vfXBbBzou"},"outputs":[],"source":["from collections import defaultdict\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","import torch.distributions as dist\n","from copy import deepcopy\n","from typing import List, Tuple\n","import time\n","import numpy as np\n","from data import load_ndfa, load_brackets\n","import logging\n","import random\n","import pandas as pd\n","import matplotlib.pyplot as plt \n","\n","logging.basicConfig(level='DEBUG', format='%(asctime)s - %(message)s')\n","RANDOM_SEED = 10\n","\n","\n","dataset_loaders = {\n","    'ndfa' : load_ndfa,\n","    'brackets': load_brackets\n","}\n","    \n","np.random.seed(RANDOM_SEED)\n","\n","def prepare_batches(x_train, i2w, w2i, max_chars_per_batch):\n","    dict_size = len(i2w)\n","    \n","    # w2i['.pad'] = 0\n","    pad_val = w2i['.pad']\n","    # w2i['.start'] = 1\n","    start_val = w2i['.start']\n","    # w2i['.end'] = 2\n","    end_val = w2i['.end']\n","\n","    for x in x_train:\n","        x.insert(0, start_val)\n","        x.append(end_val)\n","\n","    sizes = defaultdict(list)\n","    for x in x_train:\n","        sizes[len(x)].append(x)\n","\n","    t_sizes = dict()\n","    for k, v in sizes.items():\n","        t_sizes[k] = torch.tensor(v, dtype=torch.long)\n","    \n","    batches = []\n","    for _, x_tensor in t_sizes.items():\n","        x_tensor_len, n_chars = x_tensor.shape\n","        \n","        # Shift input left to create output tensor\n","        shifted_input = x_tensor[:, 2:]\n","        \n","        # Make column with padding value\n","        start_pad = start_val * torch.ones(x_tensor_len, dtype=torch.long)\n","\n","        empty_pad = pad_val * torch.ones(x_tensor_len, dtype=torch.long)\n","\n","        # Append padding to output tensor\n","        y_tensor = torch.column_stack([start_pad, shifted_input, empty_pad.T])\n","\n","        assert x_tensor.shape == y_tensor.shape\n","\n","        # Split into batches\n","        batch_size = max_chars_per_batch // n_chars\n","        x_batches = torch.split(x_tensor, batch_size)\n","        y_batches = torch.split(y_tensor, batch_size)\n","        \n","        # Create One-Hot Encodings of the output\n","        # TODO probably there is a smarter way to do one hots over the whole dict\n","        y_oh_batches = list()\n","        for y in y_batches:\n","            b, chrs = y.shape\n","            one_hots = torch.zeros(b,chrs, dict_size, dtype=torch.long)\n","            for bi in range(y.shape[0]):\n","                y_one_hot = torch.zeros(chrs, dict_size, dtype=torch.long)\n","                for el in range(chrs):\n","                    y_one_hot[el][y[bi,el]] = 1\n","                one_hots[bi, :, :] = y_one_hot\n","            y_oh_batches.append(one_hots)\n","        \n","        assert len(x_batches) == len(y_oh_batches)\n","        batches.extend(list(zip(x_batches, y_oh_batches)))\n","    \n","    np.random.shuffle(batches)\n","    return batches\n","\n","class recurNet(nn.Module):\n","\n","    def __init__(self, embedding_dim = 32, hidden_size = 16, vocab_size = 15, num_layers=1):\n","        super().__init__()\n","        self.embedding_dim = embedding_dim\n","        self.hidden_size = hidden_size\n","        self.vocab_size = vocab_size\n","        self.layer1 = nn.Embedding(num_embeddings = vocab_size, embedding_dim = embedding_dim)\n","\n","        self.layer2 = nn.LSTM(input_size = embedding_dim, hidden_size = hidden_size, num_layers=num_layers, batch_first=True)\n","        \n","        self.layer3 = nn.Linear(hidden_size, vocab_size)\n","\n","    def forward(self, input):\n","        # b, n_chrs = input.shape\n","        emb = self.layer1(input)\n","        # assert emb.shape == (b, n_chrs, self.embedding_dim)\n","                    \n","        lstm, (_, _) = self.layer2(emb)\n","\n","        # assert lstm.shape == (b, n_chrs, self.hidden_size)\n","        output = self.layer3(lstm)\n","        # assert output.shape == (b, n_chrs, self.vocab_size)\n","\n","        return output\n","        \n","def print_some_batches(batches, i2w):\n","    for x,y in batches:\n","        i = random.choice(list(range(len(x))))\n","        print(f'Input | {\" \".join(decode(x[i], i2w))}')\n","        print(f'Output | {\" \".join(decode(y[i].argmax(1), i2w))}')\n","\n","def compute_grad_norm(model) -> float:\n","    total_norm = 0\n","    for p in model.parameters():\n","        param_norm = p.grad.detach().data.norm(2)\n","        total_norm += param_norm.item() ** 2\n","    total_norm = total_norm ** (1. / 2)\n","    return total_norm\n","\n","def train(model: nn.Module, epochs : int, batches: List[Tuple[torch.Tensor, torch.Tensor]], device: torch.device, lr: float, loss_print_freq: int=30):\n","    model.to(device)\n","\n","    criterion = nn.CrossEntropyLoss(reduction='sum')\n","    optimizer = optim.Adam(model.parameters(), lr)\n","    \n","    # Capture training starting time\n","    ts_train = time.perf_counter()\n","\n","    running_loss = 0\n","    \n","    # list for training progress capturing\n","    data = list()\n","    for epoch in range(epochs):\n","        \n","        # Capture epoch starting time\n","        ts = time.perf_counter()\n","        \n","        \n","        for i, (x,one_hots) in enumerate(batches):\n","            x, one_hots = x.to(device), one_hots.to(device)\n","            \n","            optimizer.zero_grad()\n","\n","            out = model(x)\n","            \n","            loss = criterion(out, one_hots.type(torch.float32))\n","            \n","            # divide by batch and # of tokens\n","            loss /= one_hots.shape[0]* one_hots.shape[1]\n","            \n","            loss.backward()\n","\n","            optimizer.step()\n","            running_loss += loss.item()\n","            \n","            if i % loss_print_freq == 0: #print every 1000 batches\n","                logging.info('[%d, %5d] loss: %.3f ' %\n","                    (epoch +1, i+1, running_loss / loss_print_freq))\n","                running_loss = 0.0\n","            grad_norm = compute_grad_norm(model)\n","            data.append({'update' : i, 'epoch': epoch, 'loss': loss.item(), 'gradient_norm' : grad_norm})\n","        logging.info(f'Epoch took: {time.perf_counter()-ts:.2f}s')\n","    \n","    logging.info(f'Finished training. {epochs} epochs took: {time.perf_counter()-ts_train:.2f}s')\n","    return data, model\n","\n","def sample(lnprobs, temperature=1.0):\n","    \"\"\"\n","    Sample an element from a categorical distribution\n","    :param lnprobs: Outcome logits :param temperature: Sampling temperature. 1.0 follows the given\n","    distribution, 0.0 returns the maximum probability element.\n","    :return: The index of the sampled element. \"\"\" \n","    if temperature == 0.0:\n","        return lnprobs.argmax()\n","    p = F.softmax(lnprobs / temperature, dim=0) \n","    cd = dist.Categorical(p)\n","    return cd.sample()\n","\n","    \n","def decode(seq, i2w):\n","    return [i2w[tok] for tok in seq]\n","\n","def sample_model(model: nn.Module, seed_seq: List[int], end_token : int, device: torch.device, max_len:int=20, temperature: float =1.0):\n","    seed_seq = deepcopy(seed_seq)\n","    if type(seed_seq) is not list:\n","      seed_seq = seed_seq.tolist()\n","    assert len(seed_seq) < max_len\n","    with torch.no_grad():\n","        while len(seed_seq) <= max_len and seed_seq[-1] != end_token:\n","            seed_tensor = torch.LongTensor(seed_seq).view(1,-1)\n","            seed_tensor = seed_tensor.to(device)\n","        \n","            logits = model(seed_tensor)\n","            \n","            logits = logits.cpu().squeeze(0)\n","            last_logits = logits[-1, :]\n","\n","            out_tok = int(sample(last_logits, temperature))\n","            seed_seq.append(out_tok)\n","        if len(seed_seq) > max_len:\n","          print('Generated sequence too long')\n","    return seed_seq\n","\n","def delete_by_indices(lst, indices):\n","    indices_as_set = set(indices)\n","    return [ lst[i] for i in range(len(lst)) if i not in indices_as_set ]\n","\n","def eval_ndfa(samples, w2i, i2w):\n","  words = (['abc!', 'uvw!', 'klm!'])\n","  abc = [w2i[x] for x in words[0]]\n","  uvw =  [w2i[x] for x in words[1]]\n","  klm =  [w2i[x] for x in words[2]]\n","  words = [abc, uvw, klm]\n"," \n","  correct = 0\n","  for sample in samples:\n","    \n","    # sample =sample[0].tolist()\n","    \n","    # Delete .start and .end\n","\n","    sample = sample[1:-1]\n","    # sample.pop(0)\n","    print(\" \".join(decode(sample, i2w)))\n","    \n","    # sample.pop(-1)\n","\n","    if sample[0] != w2i['s'] or sample[-1] != w2i['s']:\n","      print('error | Not start / end with s')\n","      continue\n","    \n","    if w2i['.unk'] in sample or w2i['.start'] in sample:\n","      print('error | unk or start in middle')\n","      continue\n","    \n","    # First and last element MUST BE s at this point, delete them:\n","    \n","    if(len(sample) < 2): continue\n","    sample.pop(0)\n","    \n","    sample.pop(-1)\n","\n","    if(len(sample) == 0): \n","      correct += 1\n","      continue\n","\n","    if w2i['s'] in sample:\n","      print('error | rogue s spotted')\n","      continue\n","    \n","    if len(sample) % 4 != 0:\n","      print('error | words not % 4')\n","      continue\n","\n","    if sample[0:4] == words[0]:\n","      while len(sample) >= 4:\n","        sample = delete_by_indices(sample, [0,1,2,3])\n","      \n","        if len(sample) == 0: \n","          correct += 1\n","          continue\n","\n","        if sample[0:4] != words[0]:\n","          print('error | different word 0 or sth')\n","          continue \n","\n","    if sample[0:4] == words[1]:\n","      while len(sample) >= 4:\n","        sample = delete_by_indices(sample, [0,1,2,3])\n","        if len(sample) == 0:\n","           correct += 1\n","           continue\n","\n","        if sample[0:4] != words[1]:\n","          print('error | different word 1 or sth')\n","          continue \n","\n","    if sample[0:4] == words[2]:\n","      while len(sample) >= 4:\n","        sample = delete_by_indices(sample, [0,1,2,3])\n","       \n","        if len(sample) == 0:\n","           correct += 1\n","           continue\n","\n","        if sample[0:4] != words[2]:\n","          print('error | different word or sth')\n","          continue \n","\n","  accuracy = correct / len(samples[0])\n","  \n","  return accuracy\n","\n","\n","\n","def main(dataset: str, max_chars_per_batch: int, net_hparams, n_samples: int, max_len: int, temperature: float, device, loss_fig='q456.png'):\n","    logging.info(f'Loading dataset: {dataset}')\n","    dataset_loader = dataset_loaders[dataset]\n","    x_train, (i2w, w2i) = dataset_loader(n=150_000)\n","    \n","    logging.info(f'Creating batches of max chars: {max_chars_per_batch}')\n","    batches = prepare_batches(x_train, i2w, w2i, max_chars_per_batch)\n","\n","\n","    logging.info(f'Training on: {device}')\n","\n","    model = recurNet(\n","        embedding_dim=net_hparams.EMB_DIM, \n","        num_layers=net_hparams.N_LAYERS,\n","        hidden_size=net_hparams.N_HIDDEN, \n","        vocab_size=len(i2w)\n","    )\n","    \n","    data, model = train(\n","        model=model,\n","        epochs=net_hparams.EPOCHS, \n","        batches=batches, \n","        device=device,\n","        lr=net_hparams.LEARNING_RATE\n","    )\n","\n","    df = pd.DataFrame(data)\n","\n","    # logging.info(f'saving progress to: {loss_fig}')\n","    # df.groupby(by='epoch').mean()['loss'].plot()\n","    # plt.savefig(loss_fig)\n","\n","    return model, w2i, i2w, data\n","\n","def generate_samples(seq, model, n_samples, device, max_len, temperature):\n","\n","    # logging.debug(f'Sampling from model with init seed: {\", \".join(decode(seq, i2w))}')\n","\n","    samples = []\n","    for i in range(n_samples):\n","        out_seq = sample_model(model=model, seed_seq=seq, end_token= w2i['.end'], device=device, max_len=max_len, temperature=temperature)\n","        out_seq_str = decode(out_seq, i2w)\n","        # logging.debug(f'Output-{i}: {\", \".join(out_seq_str)} [len={len(out_seq)}]')\n","        samples.append(out_seq)\n","    return samples\n","\n","def isValid(s):\n","  d={'(':')'}\n","  stack=[]\n","  opening= list(d.keys()) # ( \n","  closing=list(d.values()) # ) \n","  for c in s:\n","    if c in opening:\n","      stack.append(c)\n","    elif c in closing:\n","      if stack==[] or d[stack.pop()]!=c:\n","        return False\n","  return(stack==[])\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":686,"status":"ok","timestamp":1638998721537,"user":{"displayName":"Bartek Boczek","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04109376448711217387"},"user_tz":-60},"id":"UzChTgGJBzo3"},"outputs":[],"source":["MAX_CHARS_PER_BATCH = 10000\n","DATASET = 'ndfa'\n","TEMPERATURE = 1.0\n","\n","EVAL_N_SAMPLES = 10\n","EVAL_SEQ_MAX_LEN = 20"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":32177,"status":"ok","timestamp":1638996284451,"user":{"displayName":"Bartek Boczek","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04109376448711217387"},"user_tz":-60},"id":"Z4-9XuQju4ri","outputId":"2f678cc5-6edb-4595-b2d8-9c1900d8fcf5"},"outputs":[],"source":["class HParams:\n","    EMB_DIM = 32\n","    N_HIDDEN = 16\n","    N_LAYERS = 1\n","    EPOCHS = 3\n","    LEARNING_RATE = 0.01\n","\n","device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu') \n","DATASET = 'ndfa'\n","model, w2i, i2w, data = main(\n","    dataset=DATASET,\n","    max_chars_per_batch=MAX_CHARS_PER_BATCH,\n","    net_hparams=HParams,\n","    n_samples=EVAL_N_SAMPLES,\n","    max_len=EVAL_SEQ_MAX_LEN,\n","    temperature=TEMPERATURE,\n","    device=device\n","\n",")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":578},"executionInfo":{"elapsed":1035,"status":"ok","timestamp":1639000896698,"user":{"displayName":"Bartek Boczek","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04109376448711217387"},"user_tz":-60},"id":"M9wW0onXBzo5","outputId":"5c445485-77a7-4ebe-d990-882aebc954f6"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","\n","df = pd.DataFrame(data)\n","df['epoch'] = df['epoch'] + 1\n","\n","plt.figure()\n","df.groupby(by='epoch').mean()['loss'].plot()\n","plt.ylabel('loss')\n","plt.figure()\n","df.groupby(by='epoch').mean()['gradient_norm'].plot()\n","plt.ylabel('gradient_norm')\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"23OjVGvfBzo7"},"outputs":[],"source":["test_sequences = [\n","    [w2i['.start'], w2i['s'], w2i['k'], w2i['l']],\n","    [w2i[c] for c in '.start s a b c ! a '.split()]\n","]\n","\n","def eval_ndfa_on_test_sequences(model, device, test_sequences):\n","    for seq in test_sequences:\n","        print(f'input | {\" \".join(decode(seq,i2w))} [{len(seq)}]')\n","        samples = generate_samples(seq, model, 10, device, EVAL_SEQ_MAX_LEN, TEMPERATURE)\n","        acc = eval_ndfa(samples, w2i, i2w)\n","        print(f'Accuracy: {acc}')\n","\n","eval_ndfa_on_test_sequences(model, device, test_sequences)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":398},"executionInfo":{"elapsed":9378,"status":"error","timestamp":1639001679325,"user":{"displayName":"Bartek Boczek","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04109376448711217387"},"user_tz":-60},"id":"Dre4C8sxBzo-","outputId":"cf74090e-e62c-4ded-ae9a-2e9767ad0918"},"outputs":[],"source":["MAX_CHARS_PER_BATCH = 10000\n","device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu') \n","DATASET = 'brackets'\n","class HParams:\n","    EMB_DIM = 32\n","    N_HIDDEN = 16\n","    N_LAYERS = 1\n","    EPOCHS = 3\n","    LEARNING_RATE = 0.01\n","\n","\n","model, w2i, i2w, data = main(\n","    dataset=DATASET,\n","    max_chars_per_batch=MAX_CHARS_PER_BATCH,\n","    net_hparams=HParams,\n","    n_samples=EVAL_N_SAMPLES,\n","    max_len=EVAL_SEQ_MAX_LEN,\n","    temperature=TEMPERATURE,\n","    device=device\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":558},"executionInfo":{"elapsed":699,"status":"ok","timestamp":1639001405758,"user":{"displayName":"Bartek Boczek","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04109376448711217387"},"user_tz":-60},"id":"Tm4-hYOoteky","outputId":"b7d268be-b5f0-4018-9331-dfc1748224e1"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","\n","df = pd.DataFrame(data)\n","plt.figure()\n","df.groupby(by='epoch').mean()['loss'].plot()\n","plt.ylabel('loss')\n","plt.figure()\n","df.groupby(by='epoch').mean()['gradient_norm'].plot()\n","plt.ylabel('gradient_norm')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":326,"status":"ok","timestamp":1639001687280,"user":{"displayName":"Bartek Boczek","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04109376448711217387"},"user_tz":-60},"id":"t9NOMptn1cU_"},"outputs":[],"source":["#torch.save(model, 'bracket.pt')\n","model = torch.load('bracket.pt',map_location=torch.device('cpu'))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":1011,"status":"ok","timestamp":1639001689191,"user":{"displayName":"Bartek Boczek","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04109376448711217387"},"user_tz":-60},"id":"3l4rrNpp3G1P"},"outputs":[],"source":["dataset_loader = dataset_loaders['brackets']\n","x_train, (i2w, w2i) = dataset_loader(n=150_000)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1639001690067,"user":{"displayName":"Bartek Boczek","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04109376448711217387"},"user_tz":-60},"id":"M3wingjXAQaZ"},"outputs":[],"source":["def eval_brackets_on_test_sequences(model, device, test_sequences,n_generate = 10, max_len=100):\n","    acc = []\n","    failed = 0\n","    \n","    for seq in test_sequences:\n","        print(f'input | [len: {len(seq)}] {\" \".join(decode(seq,i2w))} ')\n","        \n","        samples = generate_samples(seq, model, n_generate, device, max_len, TEMPERATURE)\n","        for s in samples:\n","            if s[0] == w2i['.start']:\n","              s = s[1:]\n","            if s[-1] == w2i['.end']:\n","              s = s[:-1]\n","\n","            # print(f'[len: {len(s)}]', ' '.join(decode(s,i2w)))\n","            str_brackets = ''.join(decode(s,i2w))\n","            if not isValid(str_brackets):\n","              # print('Sample INVALID')\n","              failed +=1\n","      \n","        print(f'{failed}/{n_generate} failed')\n","        acc.append(failed/n_generate)\n","        failed = 0\n","    return acc\n","    "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":503,"status":"ok","timestamp":1639001759817,"user":{"displayName":"Bartek Boczek","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04109376448711217387"},"user_tz":-60},"id":"IBEcZmfBA0Xr","outputId":"94ee6a0c-2779-4baf-f58a-ebc6723a4bdc"},"outputs":[],"source":["import random\n","\n","test_sequences = []\n","for i in range(5):\n","  seq = random.choice([s for s in x_train if len(s) > 4])\n","  idx = random.randint(1,len(seq)-1)\n","  o_seq = [w2i['.start']] + seq[0:idx]\n","  test_sequences.append(o_seq)\n","\n","for i in range(5):\n","  seq = random.choice([s for s in x_train if len(s) > 15])\n","  idx = random.randint(1,len(seq)-1)\n","  o_seq = [w2i['.start']] + seq[0:idx]\n","  test_sequences.append(o_seq)\n","\n","for i in range(5):\n","  seq = random.choice([s for s in x_train if len(s) > 300])\n","  idx = random.randint(1,len(seq)-1)\n","  o_seq = [w2i['.start']] + seq[0:idx]\n","  test_sequences.append(o_seq)\n","\n","[len(t) for t in test_sequences]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":818},"executionInfo":{"elapsed":51358,"status":"error","timestamp":1639001817427,"user":{"displayName":"Bartek Boczek","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04109376448711217387"},"user_tz":-60},"id":"AkkXyxLg-XER","outputId":"bc89f904-7a28-4a5b-c5e5-f9f428e730fe"},"outputs":[],"source":["acc = eval_brackets_on_test_sequences(model.to(device), device,test_sequences, max_len=max(len(x) for x in x_train)+100)\n","print(acc)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DVUykT7j9Kbx"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"q567.ipynb","provenance":[]},"interpreter":{"hash":"86794363eb91970d292a6431d143b620da58dd3d276a700aac3c699fb5de6d5a"},"kernelspec":{"display_name":"Python 3.9.7 64-bit ('dl': conda)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":0}
